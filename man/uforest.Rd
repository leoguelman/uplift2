% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/uforest.R
\name{uforest}
\alias{uforest}
\alias{uforest.formula}
\alias{print.uforest}
\title{Fitting uplift random forest.}
\usage{
\method{uforest}{formula}(formula, data, na.action, classLevel = NULL,
  treatLevel = NULL, control = uforest_control(...), ...)

\method{print}{uforest}(x, ...)
}
\arguments{
\item{formula}{A model formula of the form y ~ x1 + ....+ xn + trt(), where
the left-hand side corresponds to the observed response, the right-hand side
corresponds to the predictors, and 'trt' is the special expression to mark
the treatment term. At the moment, \code{uforest} only handles binary
responses.}

\item{data}{A data frame in which to interpret the variables named in the
formula.}

\item{na.action}{A missing-data filter function.}

\item{classLevel}{A character string for the class of interest. Defaults to
the last level of the factor.}

\item{treatLevel}{A character string for the treatment level of interest.
Defaults to the last level of the treatment factor.}

\item{control}{A list with control parameters, see \code{\link{uforest_control}}.}

\item{\dots}{Arguments passed to \code{\link{uforest_control}}.}

\item{x}{An object of class \code{"uforest"}}
}
\value{
An object of class \code{"uforest"}.
}
\description{
\code{uforest} implements uplift random forests.
}
\details{
\code{uforest} builds a sequence of de-correlated uplift trees (see
\code{\link{utree}}) fitted on bootstrap samples of the training data.
Additionally, the best split at each node is selected among a subset of
predictors randomly selected at that node. See Guelman et al. (2015) for
details.
}
\examples{

set.seed(1)
df <- sim_uplift(n = 1000, p = 50, response = "binary")
form <- create_uplift_formula(x = names(df)[-c(1:3)], y = "y", trt = "T")
fit <- uforest(form, data = df, maxdepth = 3, ntree = 10, nCore = 2)
fit
t1 <- fit$forest[[1]] # see structure of first tree
plot(t1,  main = "first tree...", gp = grid::gpar(cex = 0.5))
}
\references{
Guelman, L., Guillen, M., and Perez-Marin A.M. (2015). "A decision support
framework to implement optimal personalized marketing interventions." Decision
Support Systems, Vol. 72, pp. 24--32.

Hothorn, T., Hornik, K. and Zeileis, A. (2006). "Unbiased recursive
partitioning: A conditional inference framework". Journal of Computational and
Graphical Statistics, 15(3): 651--674.

Rzepakowski, Piotr and Jaroszewicz, Szymon. (2011). "Decision trees for uplift
modeling with single and multiple treatments". Knowledge and Information
Systems, 32(2) 303--327.

Strasser, H. and Weber, C. (1999). "On the asymptotic theory of permutation
statistics". Mathematical Methods of Statistics, 8: 220--250.

Su, X., Tsai, C.-L., Wang, H., Nickerson, D. M. and Li, B. (2009). "Subgroup
Analysis via Recursive Partitioning". Journal of Machine Learning Research 10,
141--158.
}
\author{
Leo Guelman \email{leo.guelman@gmail.com}
}
